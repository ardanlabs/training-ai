{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering, Profiling, and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ml workflow](https://docs.google.com/drawings/d/e/2PACX-1vQ-v8AikdWJxzh5WdNTi9dhv-J6YF4DbbFJ9YQbAKbnljVV0MozzUX5TGhJ1NhtRcJrKdu_sh2QC_hy/pub?w=1165&h=662)\n",
    "\n",
    "Let's dive in and see how we can complete the various parts of this ML workflow with Go. In particular, let's look at how we can import, parse, manipulate, and profile data with Go. Note, there are innumerable types and formats of data that you might have to deal with in an ML/AI workflow (CSV, JSON, Parquet, Avro, etc.), and we won't cover all of them. Rather, we will highlight a few of the main Go packages that you can utilize for data gathering, profiling, and cleaning.\n",
    "\n",
    "We will look at two different example data sets in this example notebook:\n",
    "- a [Game of Thrones data set](https://github.com/chrisalbon/war_of_the_five_kings_dataset) in CSV format, and\n",
    "- an [emoji data set](https://www.kaggle.com/sanjayaw/emosim508) in JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "    \"os\"\n",
    "    \"fmt\"\n",
    "    \"encoding/csv\"\n",
    "    \"encoding/json\"\n",
    "    \"io/ioutil\"\n",
    "    \"strings\"\n",
    "    \"strconv\"\n",
    "    \n",
    "    \"gonum.org/v1/plot\"\n",
    "    \"gonum.org/v1/plot/plotter\"\n",
    "    \"gonum.org/v1/plot/plotutil\"\n",
    "    \"gonum.org/v1/plot/vg\"\n",
    "    \"github.com/kniren/gota/dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and parsing CSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This portion of the example will utilize a [Game of Thrones data set](https://github.com/chrisalbon/war_of_the_five_kings_dataset) to illustrate various CSV gathering, parsing, and manipulation techniques. The data set represents the battles in the War of the Five Kings from George R.R. Martin's A Song Of Ice And Fire series.\n",
    "\n",
    "We will first illustrate parsing the CSV file with stdlib's `encoding/csv`, along with some basic manipulations. Then we will utilize a couple of third party packages to further profile the data and build up some intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import with `encoding/csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Open the csv file at ../../data/5kings_battles_v1.csv.\n",
    "file, err := os.Open(\"../data/5kings_battles_v1.csv\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a new CSV reader.\n",
    "reader := csv.NewReader(file)\n",
    "\n",
    "// Read in all the records via the CSV reader method ReadAll.\n",
    "records, err := reader.ReadAll()\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "// Close the file.\n",
    "file.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Let's get a sense of what the records look like\n",
    "// by printing a few of them.\n",
    "for idx, record := range records {\n",
    "    \n",
    "    // Examine the header row.\n",
    "    if idx == 0 {\n",
    "        fmt.Println(\"Header: \", record)\n",
    "        continue\n",
    "    }\n",
    "    \n",
    "    // Print a few of the actual records.\n",
    "    fmt.Printf(\"\\nname: %s\\nyear: %s\\nattacker_king: %s\\ndefender_king: %s\\nattacker_1: %s\\n\", record[0], record[1], record[3], record[4], record[5])\n",
    "    if idx > 5 {\n",
    "        break\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data parsing and manipulations with stdlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times when prepping data for ML/AI models, we are interested in only a subset of the features/labels. In addition, you will notice that the data imported via `encoding/csv` is all represented as slices of strings. As such, lets':\n",
    "\n",
    "1. Create a new slice of structs with only the fields of interest, and\n",
    "2. Parse certain fields into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Define a struct with the fields we want to keep.\n",
    "type Battle struct{\n",
    "    Name string\n",
    "    Year int\n",
    "    AttackerWin bool\n",
    "    AttackerSize int\n",
    "    DefenderSize int\n",
    "    Region string\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a slice of Battle.\n",
    "var battles [38]Battle\n",
    "\n",
    "// Loop over the records.\n",
    "for idx, record := range records {\n",
    "    \n",
    "    // Skip the header row.\n",
    "    if idx == 0 {\n",
    "        continue\n",
    "    }\n",
    "    \n",
    "    // Create a Battle value.\n",
    "    battle := Battle{\n",
    "        Name: record[0],\n",
    "        Region: record[21],\n",
    "    }\n",
    "    \n",
    "    // Parse the year.\n",
    "    year, err := strconv.Atoi(record[1])\n",
    "    if err != nil {\n",
    "        fmt.Println(err)\n",
    "        break\n",
    "    }\n",
    "    battle.Year = year\n",
    "    \n",
    "    // Parse the outcome.\n",
    "    var attackerWin bool\n",
    "    if record[11] == \"win\" {\n",
    "        attackerWin = true\n",
    "    }\n",
    "    battle.AttackerWin = attackerWin\n",
    "    \n",
    "    // Parse the attacker size.\n",
    "    if record[15] != \"\" {\n",
    "        attackerSize, err := strconv.Atoi(record[15])\n",
    "        if err != nil {\n",
    "            fmt.Println(err)\n",
    "            break\n",
    "        }\n",
    "        battle.AttackerSize = attackerSize\n",
    "    }\n",
    "    if record[16] != \"\" {\n",
    "        defenderSize, err := strconv.Atoi(record[16])\n",
    "        if err != nil {\n",
    "            fmt.Println(err)\n",
    "            break\n",
    "        }\n",
    "        battle.DefenderSize = defenderSize\n",
    "    }\n",
    "    \n",
    "    // Add the data to our new slice.\n",
    "    battles[idx-1] = battle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Output a couple of the parsed battles to stdout.\n",
    "fmt.Println(battles[0])\n",
    "fmt.Println(battles[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic profiling with stdlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of battles in each year and each region observed in the battle data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a map to hold the frequencies.\n",
    "yearFrequencies := make(map[int]int)\n",
    "regionFrequencies := make(map[string]int)\n",
    "\n",
    "// Loop over records.\n",
    "for _, battle := range battles {\n",
    "    \n",
    "    // Increment a counter for the relevant year.\n",
    "    yearFrequencies[battle.Year]++\n",
    "    \n",
    "    // Increment a counter for the relevant region.\n",
    "    regionFrequencies[battle.Region]++\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Output the year results to stdout.\n",
    "fmt.Println(\"Battles per year:\\n-------------------------------\\n\")\n",
    "for k, v := range yearFrequencies {\n",
    "    fmt.Printf(\"year: %d\\ncount: %d\\n\\n\", k, v)\n",
    "}\n",
    "\n",
    "fmt.Println(\"Battles per region:\\n-------------------------------\\n\")\n",
    "for k, v := range regionFrequencies {\n",
    "    fmt.Printf(\"region: %s\\ncount: %d\\n\\n\", k, v)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling and visualization with third-party packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing some of the counts above, gives us a little intuition about the text fields in the battle data. However, before moving forward with the data, we should make sure that we have a sense about the centrality and spread of our numerical data. Essentially this means that we would like to get some intuition about (1) where are most of our numerical values, and (2) how are those values spread out across their range. \n",
    "\n",
    "To figure this out, let's use a convenient DataFrame package called `gota`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Open the CSV file.\n",
    "f, err := os.Open(\"../data/5kings_battles_v1.csv\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "// Create a dataframe from the CSV file.\n",
    "// The types of the columns will be inferred.\n",
    "battleDF := dataframe.ReadCSV(f)\n",
    "f.Close()\n",
    "\n",
    "// Select out the columns that we would like to use.\n",
    "battleDF = battleDF.Select([]string{\"name\", \"year\", \"attacker_size\", \"defender_size\", \"region\"})\n",
    "\n",
    "// Show the nice structure that gota inferred from our data.\n",
    "fmt.Println(battleDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Now let's output the statistics that\n",
    "// will give us some intuition about centrality\n",
    "// and spread of the numerical columns.\n",
    "battleDF.Select([]string{\"year\", \"attacker_size\", \"defender_size\"}).Describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can clearly see the statistical measures for the `year` column, but we see a bunch of NaN's in the size columns. This is a result of having missing values in those columns, which is also good to know as we are profiling our data. We will attempt to deal with these missing values in an exercise.\n",
    "\n",
    "Now, numbers are great, and they can give us some intuition about our data, but visualizations of the data are also super useful. Let's use `gonum.org/v1/plot` to create some plots showing various aspects of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a new plot value that will allow us to\n",
    "// plot the battle counts per region. \n",
    "p, err := plot.New()\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "// Label the plot and the y axis.\n",
    "p.Title.Text = \"battles per region\"\n",
    "p.Y.Label.Text = \"count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a plotter.Values value that will contain\n",
    "// the data we want to plot.\n",
    "counts := make(plotter.Values, len(regionFrequencies))\n",
    "\n",
    "// Create a slice of strings to contain our region names.\n",
    "regions := make([]string, len(regionFrequencies))\n",
    "\n",
    "// Loop over our parsed data (the data we parsed into structs)\n",
    "// to extract the regions and counts corresponding\n",
    "// to those regions.\n",
    "idx := 0\n",
    "for  key, value := range regionFrequencies {\n",
    "    \n",
    "    // Convert the integer to floats, which is required\n",
    "    // to generate the plot.\n",
    "    counts[idx] = float64(value)\n",
    "    \n",
    "    // Extract the region and take care of any new line characters.\n",
    "    regions[idx] = strings.Replace(key,\" \",\"\\n\",-1)\n",
    "    \n",
    "    // Advance the index.\n",
    "    idx++\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a new bar chart.\n",
    "w := vg.Points(20)\n",
    "bars, err := plotter.NewBarChart(counts, w)\n",
    "if err != nil {\n",
    "\tfmt.Println(err)\n",
    "}\n",
    "\n",
    "// Add the bars to the plot.\n",
    "p.Add(bars)\n",
    "\n",
    "// Add the x labels.\n",
    "p.NominalX(regions...)\n",
    "\n",
    "// Save the plot.\n",
    "if err := p.Save(6*vg.Inch, 3*vg.Inch, \"barchart.png\"); err != nil {\n",
    "\tfmt.Println(err)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Open the plot and display it inline\n",
    "f, err := os.Open(\"barchart.png\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "plotBytes, err := ioutil.ReadAll(f)\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "f.Close()\n",
    "\n",
    "display.PNG(plotBytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and parsing JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This portion of the example will utilize an [emoji data set called EmoSim508](https://www.kaggle.com/sanjayaw/emosim508) to illustrate various JSON gathering, parsing, and manipulation techniques. EmoSim508 is the largest emoji similarity dataset that provides emoji similarity scores for 508 carefully selected emoji pairs. The most frequently co-occurring emoji pairs in a tweet corpus (that contains 147 million tweets) was used for creating the dataset and each emoji pair was annotated for its similarity using 10 human annotators. EmoSim508 dataset also consists of the emoji similarity scores generated from 8 different emoji embedding models proposed in \"A Semantics-Based Measure of Emoji Similarity\" paper by Wijeratne et al. \n",
    "\n",
    "We will illustrate parsing the JSON file with stdlib's `encoding/json`, along with some basic manipulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and parsing with `encoding/json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// First we need to create structs that define the\n",
    "// structure of the JSON that we expect.\n",
    "type emoji struct{\n",
    "    Unicodelong  string `json:\"unicodelong\"`\n",
    "    Unicodeshort string `json:\"unicodeshort\"`\n",
    "    Title        string `json:\"title\"`\n",
    "}\n",
    "\n",
    "type emojiTuple struct{\n",
    "    EmojiOne emoji `json:\"emojiOne\"`\n",
    "    EmojiTwo emoji `json:\"emojiTwo\"`\n",
    "}\n",
    "\n",
    "type emojiSimilarityMetrics struct{\n",
    "    Google_Sense_Label        float32\n",
    "    Twitter_Sense_Def         float32\n",
    "    Google_Sense_All          float32\n",
    "    Google_Sense_Def          float32\n",
    "    Google_Sense_Desc         float32\n",
    "    Twitter_Sense_All         float32\n",
    "    Twitter_Sense_Desc        float32\n",
    "    Twitter_Sense_Label       float32\n",
    "    Human_Annotator_Agreement float32 \n",
    "}\n",
    "\n",
    "type emojiSim struct{\n",
    "    EmojiPairId         string                 `json:\"emojiPairId\"`\n",
    "    EmojiPair           emojiTuple             `json:\"emojiPair\"`\n",
    "    EmojiPairSimilarity emojiSimilarityMetrics `json:\"emojiPairSimilarity`\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load the JSON file.\n",
    "emojiFile, err := ioutil.ReadFile(\"../data/EmoSim508.json\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "// Create an emojiSim value to hold the parsed data.\n",
    "var emojisims []emojiSim\n",
    "\n",
    "// Unmarshall the data from the file.\n",
    "if err = json.Unmarshal(emojiFile, &emojisims); err != nil {\n",
    "    fmt.Println(err)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Pretty print one of the records to see what\n",
    "// they look like.\n",
    "firstData, err := json.MarshalIndent(emojisims[0], \"\", \"  \")\n",
    "if err != nil{\n",
    "    fmt.Println(err)\n",
    "}\n",
    "fmt.Println(string(firstData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select out all of the emoji pairs where the `Human_Annotator_Agreement` is greater than 3.5, meaning that the emojis are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a slice of emojiTuple to hold the selected pairs.\n",
    "var resultPairs []emojiTuple\n",
    "\n",
    "// Loop over the parsed emoji data selecting out the emojis.\n",
    "for _, val := range emojisims {\n",
    "    if val.EmojiPairSimilarity.Human_Annotator_Agreement > 3.5{ \n",
    "        resultPairs = append(resultPairs,val.EmojiPair)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Let's see how many of the emoji pairs satisfy this requirement.\n",
    "fmt.Printf(\"Similar emojis count: %d\", len(resultPairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save all of the similar emoji pairs to an output data file. We can utilize `encoding/json` for this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Marshall the data in a pretty printed format.\n",
    "jsonString, err := json.MarshalIndent(emojisims, \"\", \"  \")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "// Write the data out to a file.\n",
    "if err = ioutil.WriteFile(\"similar_emojis.json\", jsonString, 0755); err != nil {\n",
    "    fmt.Println(err)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
