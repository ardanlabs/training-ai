{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining, Training, and Testing Models - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ml workflow](https://docs.google.com/drawings/d/e/2PACX-1vQ1XLwesZbm_TuDBPFRvbHa4XcjucvtExy3LXE05WnaAw-s6BDVQnnd4lAEUW1Qy6bs6FythuJdFVqP/pub?w=1165&h=662)\n",
    "\n",
    "Moving on from Regression, let's now try out some **Classification**. As opposed to predicting a continuous value (like weight, temperature, or stock price), classification attempts to predict whether a certain sample belongs to one class or another (e.g., fraud or not fraud). \n",
    "\n",
    "For our example, we will be trying to predict the species of Iris flowers (our labels or classes) based on physical measurements of those Iris flowers (our features). We can do this based on a very famous data set which you can learn more about [here](https://en.wikipedia.org/wiki/Iris_flower_data_set). We will try two different kinds of models:\n",
    "\n",
    "- [k Nearest Neighbors](https://youtu.be/UqYde-LULfs)\n",
    "- [Decision Tree](https://www.cs.cmu.edu/afs/cs/academic/class/15381-s07/www/slides/041007decisionTrees1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "    \"io/ioutil\"\n",
    "    \"fmt\"\n",
    "    \"os\"\n",
    "    \"math\"\n",
    "    \"math/rand\"\n",
    "    \n",
    "    \"github.com/kniren/gota/dataframe\"\n",
    "    \"github.com/kniren/gota/series\"\n",
    "    \"gonum.org/v1/plot\"\n",
    "    \"gonum.org/v1/plot/plotter\"\n",
    "    \"gonum.org/v1/plot/plotutil\"\n",
    "    \"gonum.org/v1/plot/vg\"\n",
    "    \"gonum.org/v1/gonum/stat\"\n",
    "    \"gonum.org/v1/gonum/floats\"\n",
    "    \"github.com/sjwhitworth/golearn/knn\"\n",
    "    \"github.com/sjwhitworth/golearn/base\"\n",
    "    \"github.com/sjwhitworth/golearn/evaluation\"\n",
    "    \"github.com/sjwhitworth/golearn/trees\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// GetGraph returns the bytes corresponding to a\n",
    "// saved plot.\n",
    "func GetGraph(graphName string) ([]byte, error) {\n",
    "    \n",
    "    // Open the file.\n",
    "    infile, err := os.Open(graphName)\n",
    "    if err != nil {\n",
    "        return nil, err\n",
    "    }\n",
    "    \n",
    "    // Read in the contents of the file.\n",
    "    bytes, err := ioutil.ReadAll(infile)\n",
    "    if err != nil {\n",
    "        return nil, err\n",
    "    }\n",
    "    \n",
    "    // Close the file.\n",
    "    infile.Close()\n",
    "    \n",
    "    return bytes, err\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Open the data file.\n",
    "f, err := os.Open(\"../data/iris.csv\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "// Read in the contents to a dataframe.\n",
    "irisDF := dataframe.ReadCSV(f)\n",
    "\n",
    "// Close the file.\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Output a summary of the dataset to stdout.\n",
    "fmt.Println(irisDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile our data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of each species label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Define our unique species.\n",
    "species := []string{\"Iris-setosa\", \"Iris-virginica\", \"Iris-versicolor\"}\n",
    "\n",
    "// Count instances of the unique species.\n",
    "for _, sp := range species {\n",
    "        \n",
    "    // Create a filter for the dataframe.\n",
    "    filter := dataframe.F{\n",
    "        Colname:    \"species\",\n",
    "        Comparator: series.Eq,\n",
    "        Comparando: sp,\n",
    "    }\n",
    "    \n",
    "    // Filter the dataframe to see only the rows where\n",
    "    // the species is equal to sp.\n",
    "    filteredDF := irisDF.Filter(filter)\n",
    "    if filteredDF.Err != nil {\n",
    "        fmt.Println(filteredDF.Err)\n",
    "    }\n",
    "    \n",
    "    // Output the count.\n",
    "    fmt.Printf(\"%s count: %d\\n\", sp, filteredDF.Nrow())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a histogram for each of the float columns in the dataset and\n",
    "// output summary statistics.\n",
    "for _, colName := range irisDF.Names() {\n",
    "\n",
    "    if colName != \"species\" {\n",
    "\n",
    "        // Create a plotter.Values value and fill it with the\n",
    "        // values from the respective column of the dataframe.\n",
    "        plotVals := make(plotter.Values, irisDF.Nrow())\n",
    "        summaryVals := make([]float64, irisDF.Nrow())\n",
    "        for i, floatVal := range irisDF.Col(colName).Float() {\n",
    "            plotVals[i] = floatVal\n",
    "            summaryVals[i] = floatVal\n",
    "        }\n",
    "\n",
    "        // Make a plot and set its title.\n",
    "        p, err := plot.New()\n",
    "        if err != nil {\n",
    "            fmt.Println(err)\n",
    "        }\n",
    "        p.Title.Text = fmt.Sprintf(\"Histogram of a %s\", colName)\n",
    "\n",
    "        // Create a histogram of our values drawn\n",
    "        // from the standard normal.\n",
    "        h, err := plotter.NewHist(plotVals, 16)\n",
    "        if err != nil {\n",
    "            fmt.Println(err)\n",
    "        }\n",
    "\n",
    "        // Normalize the histogram.\n",
    "        h.Normalize(1)\n",
    "\n",
    "        // Add the histogram to the plot.\n",
    "        p.Add(h)\n",
    "\n",
    "        // Save the plot to a PNG file.\n",
    "        if err := p.Save(4*vg.Inch, 4*vg.Inch, colName+\"_hist.png\"); err != nil {\n",
    "            fmt.Println(err)\n",
    "        }\n",
    "\n",
    "        // Calculate the summary statistics.\n",
    "        meanVal := stat.Mean(summaryVals, nil)\n",
    "        maxVal := floats.Max(summaryVals)\n",
    "        minVal := floats.Min(summaryVals)\n",
    "        stdDevVal := stat.StdDev(summaryVals, nil)\n",
    "\n",
    "        // Output the summary statistics.\n",
    "        fmt.Printf(\"\\n%s\\n\", colName)\n",
    "        fmt.Printf(\"Mean: %0.2f\\n\", meanVal)\n",
    "        fmt.Printf(\"Min: %0.2f\\n\", minVal)\n",
    "        fmt.Printf(\"Max: %0.2f\\n\", maxVal)\n",
    "        fmt.Printf(\"StdDev: %0.2f\\n\\n\", stdDevVal)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Read the plot data from the first histogram.\n",
    "plotBytes, err := GetGraph(\"sepal_width_hist.png\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "    \n",
    "// Display the plot.\n",
    "display.PNG(plotBytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Read the plot data from the second histogram.\n",
    "plotBytes, err := GetGraph(\"sepal_length_hist.png\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "    \n",
    "// Display the plot.\n",
    "display.PNG(plotBytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Read the plot data from the third histogram.\n",
    "plotBytes, err := GetGraph(\"petal_width_hist.png\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "    \n",
    "// Display the plot.\n",
    "display.PNG(plotBytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Read the plot data from the fourth histogram.\n",
    "plotBytes, err := GetGraph(\"petal_length_hist.png\")\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "    \n",
    "// Display the plot.\n",
    "display.PNG(plotBytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ml workflow](https://docs.google.com/drawings/d/e/2PACX-1vSbzVQ-fJeOxZvAzbbE3yjRdB8A5WyBmHC2jz2AJTKvCcyOvZghkMVRAOvLgoGdF0mbcNPxCqRCrdIZ/pub?w=770&h=344)\n",
    "\n",
    "We will now define a kNN and decision tree model.  The kNN algorithm calculates a \"distance\" between the input features and known observations in the feature space. It then chooses the *k* nearest of of these observations based on the distance. The majority class of those k nearest neighbors is then taken to be the class corresponding to the input features.\n",
    "\n",
    "In a decision tree algorithm, a tree of if/then statements is created based on the features and labeled points of a training set. The parameters of the model that are determined during training are the ranges and ordering that determine how the if/then splits happen.\n",
    "\n",
    "**Note** - We haven't split into training and test set yet, because we are going to utilize cross validation to evaluate/validate out model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Define our kNN model.\n",
    "knnModel := knn.NewKnnClassifier(\"euclidean\", \"linear\", 2)\n",
    "\n",
    "// This is to seed the random processes involved in building the\n",
    "// decision tree.\n",
    "rand.Seed(44111342)\n",
    "\n",
    "// We will use the ID3 algorithm to build our decision tree.  Also, we\n",
    "// will start with a parameter of 0.6 that controls the train-prune split.\n",
    "tree := trees.NewID3DecisionTree(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cross validation to train/evaluate/validate our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Read in the iris data set into golearn \"instances\".\n",
    "irisData, err := base.ParseCSVToInstances(\"../data/iris.csv\", true)\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Use cross-fold validation to evaluate the kNN model\n",
    "// on 5 folds of the data set.\n",
    "cv, err := evaluation.GenerateCrossFoldValidationConfusionMatrices(irisData, knnModel, 5)\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "// Get the mean, variance and standard deviation of the accuracy for the\n",
    "// cross validation.\n",
    "mean, variance := evaluation.GetCrossValidatedMetric(cv, evaluation.GetAccuracy)\n",
    "stdev := math.Sqrt(variance)\n",
    "\n",
    "// Output the cross metrics to standard out.\n",
    "fmt.Printf(\"\\n\\nkNN Accuracy:\\n%.2f (+/- %.2f)\\n\\n\", mean, stdev*2)\n",
    "\n",
    "// Use cross-fold validation to train evaluate the tree model\n",
    "// on 5 folds of the data set.\n",
    "cv, err = evaluation.GenerateCrossFoldValidationConfusionMatrices(irisData, tree, 5)\n",
    "if err != nil {\n",
    "    fmt.Println(err)\n",
    "}\n",
    "\n",
    "mean, variance = evaluation.GetCrossValidatedMetric(cv, evaluation.GetAccuracy)\n",
    "stdev = math.Sqrt(variance)\n",
    "\n",
    "fmt.Printf(\"Decision Tree Accuracy:\\n%.2f (+/- %.2f)\\n\\n\", mean, stdev*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
